{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baccf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c875703f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.,  9.],\n",
       "          [10., 11., 12., 13., 14.],\n",
       "          [15., 16., 17., 18., 19.],\n",
       "          [20., 21., 22., 23., 24.]]]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = torch.arange(25).view(1,1,5,5).float()\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da565341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 5, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H,W = 5,5\n",
    "xs = torch.linspace(-1,1,W)\n",
    "ys = torch.linspace(-1,1,H)\n",
    "grid_y, grid_x = torch.meshgrid(ys, xs, indexing='ij')\n",
    "\n",
    "grid = torch.stack([grid_x,grid_y],dim = -1).unsqueeze(0)\n",
    "grid.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e108ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = f.grid_sample(img,grid,align_corners=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b1eafb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input:\n",
      " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14.],\n",
      "        [15., 16., 17., 18., 19.],\n",
      "        [20., 21., 22., 23., 24.]])\n",
      "output:\n",
      " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14.],\n",
      "        [15., 16., 17., 18., 19.],\n",
      "        [20., 21., 22., 23., 24.]])\n"
     ]
    }
   ],
   "source": [
    "print(\"input:\\n\", img.squeeze())\n",
    "print(\"output:\\n\", out.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a920106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.3000, 0.0000]]]])\n",
      "input:\n",
      " tensor([[ 0.,  1.,  2.,  3.,  4.],\n",
      "        [ 5.,  6.,  7.,  8.,  9.],\n",
      "        [10., 11., 12., 13., 14.],\n",
      "        [15., 16., 17., 18., 19.],\n",
      "        [20., 21., 22., 23., 24.]])\n",
      "output:\n",
      " tensor([[ 0.6000,  1.6000,  2.6000,  3.6000,  1.6000],\n",
      "        [ 5.6000,  6.6000,  7.6000,  8.6000,  3.6000],\n",
      "        [10.6000, 11.6000, 12.6000, 13.6000,  5.6000],\n",
      "        [15.6000, 16.6000, 17.6000, 18.6000,  7.6000],\n",
      "        [20.6000, 21.6000, 22.6000, 23.6000,  9.6000]])\n"
     ]
    }
   ],
   "source": [
    "disp = torch.tensor([0.3, 0.0]).view(1, 1, 1, 2)\n",
    "print(disp)\n",
    "grid_trans = grid+disp\n",
    "out_trans = f.grid_sample(img, grid_trans, align_corners=True)\n",
    "print(\"input:\\n\", img.squeeze())\n",
    "print(\"output:\\n\", out_trans.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "18aef711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "torch.Size([2])\n",
      "torch.Size([1, 5, 5, 2])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.3397,  4.3397,  2.7705,  0.0000],\n",
      "        [ 0.0000,  5.2679, 12.0000, 18.7321,  0.0000],\n",
      "        [ 0.0000,  3.6603, 19.6603,  6.0910,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]])\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "theta = math.radians(30)\n",
    "A = torch.tensor([\n",
    "    [ 2*math.cos(theta), -2*math.sin(theta)],\n",
    "    [ 2*math.sin(theta),  2*math.cos(theta)]\n",
    "]).float()   # shape (2,2)\n",
    "print(A.shape)\n",
    "b = torch.tensor([0.0, 0.0])   # translation vector\n",
    "print(b.shape)\n",
    "print(grid.shape)\n",
    "\n",
    "# base grid is (H,W,2), want (H,W,2)\n",
    "grid_affine = torch.einsum('ij,nhwj->hwi', A, grid)+b\n",
    "\n",
    "out_aff = f.grid_sample(img, grid_affine.unsqueeze(0), align_corners=True)\n",
    "\n",
    "print(out_aff.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2efedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 shape: torch.Size([2, 4])\n",
      "Q2 shape: torch.Size([5, 2, 4])\n",
      "Q3 shape: torch.Size([10, 20])\n",
      "Q4 shape: torch.Size([6])\n",
      "Q5 shape: torch.Size([30, 40, 2])\n",
      "Q6 shape: torch.Size([5, 30, 40, 2])\n",
      "Q7 shape: torch.Size([10, 20, 30, 3])\n",
      "Q8 shape: torch.Size([4, 10, 20, 30, 3])\n",
      "Q9 shape: torch.Size([50, 60, 2])\n",
      "Q10 shape: torch.Size([2, 10, 20, 30, 3])\n"
     ]
    }
   ],
   "source": [
    "# 1. Matrix multiplication (A @ B)\n",
    "A = torch.randn(2, 3)\n",
    "B = torch.randn(3, 4)\n",
    "# TODO: write your einsum\n",
    "C1 = torch.einsum('ab,bc->ac', A, B)\n",
    "print(\"Q1 shape:\", C1.shape)   # expected: (2,4)\n",
    "\n",
    "# 2. Batched matrix multiplication\n",
    "A = torch.randn(5, 2, 3)   # (N,2,3)\n",
    "B = torch.randn(5, 3, 4)   # (N,3,4)\n",
    "# TODO\n",
    "C2 = torch.einsum('nab,nbc->nac', A, B)\n",
    "print(\"Q2 shape:\", C2.shape)   # expected: (5,2,4)\n",
    "\n",
    "# --------------------------\n",
    "# Level 2: Dot product & weighted sum\n",
    "# --------------------------\n",
    "\n",
    "# 3. Pixelwise dot product over last dimension\n",
    "x = torch.randn(10, 20, 3)\n",
    "y = torch.randn(10, 20, 3)\n",
    "# TODO\n",
    "dot = torch.einsum('abc,abc -> ab', x, y)\n",
    "print(\"Q3 shape:\", dot.shape)   # expected: (10,20)\n",
    "\n",
    "\n",
    "# 4. Row-wise weighted sum (sum over W axis)\n",
    "A = torch.randn(6, 8)   # (H,W)\n",
    "w = torch.randn(6)      # (H,)\n",
    "# TODO\n",
    "row_sum = torch.einsum('ij,i->i', A, w)\n",
    "print(\"Q4 shape:\", row_sum.shape)   # expected: (6,)\n",
    "\n",
    "# --------------------------\n",
    "# Level 3: 2D Affine Warp\n",
    "# --------------------------\n",
    "\n",
    "# 5. 2D affine warp (no batch)\n",
    "A = torch.randn(2, 2)\n",
    "grid = torch.randn(30, 40, 2)   # (H,W,2)\n",
    "# TODO\n",
    "grid2 = torch.einsum('ij,hwj->hwi', A, grid)\n",
    "print(\"Q5 shape:\", grid2.shape)   # expected: (30,40,2)\n",
    "\n",
    "\n",
    "# 6. 2D affine warp with batch\n",
    "A = torch.randn(5, 2, 2)         # (N,2,2)\n",
    "grid = torch.randn(5, 30, 40, 2) # (N,H,W,2)\n",
    "# TODO\n",
    "grid2b = torch.einsum('nij,nhwj->nhwi', A, grid)\n",
    "print(\"Q6 shape:\", grid2b.shape)  # expected: (5,30,40,2)\n",
    "\n",
    "# --------------------------\n",
    "# Level 4: 3D Affine Warp\n",
    "# --------------------------\n",
    "\n",
    "# 7. 3D affine warp (no batch)\n",
    "A = torch.randn(3, 3)\n",
    "grid = torch.randn(10, 20, 30, 3)   # (D,H,W,3)\n",
    "# TODO\n",
    "grid3 = torch.einsum('ij,dhwj->dhwi', A, grid)\n",
    "print(\"Q7 shape:\", grid3.shape)     # expected: (10,20,30,3)\n",
    "\n",
    "\n",
    "# 8. 3D affine warp with batch\n",
    "A = torch.randn(4, 3, 3)             # (N,3,3)\n",
    "grid = torch.randn(4, 10, 20, 30, 3) # (N,D,H,W,3)\n",
    "# TODO\n",
    "grid3b = torch.einsum('nij,ndhwj->ndhwi', A, grid)\n",
    "print(\"Q8 shape:\", grid3b.shape)     # expected: (4,10,20,30,3)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Level 5: Displacement add\n",
    "# --------------------------\n",
    "\n",
    "# 9. 2D displacement addition using einsum (no '+')\n",
    "I = torch.eye(2)\n",
    "grid = torch.randn(50, 60, 2)\n",
    "disp = torch.randn(50, 60, 2)\n",
    "# TODO: use einsum to compute grid + disp = I @ grid + disp\n",
    "grid_disp = torch.einsum('ij,hwj->hwi', I, grid) + disp\n",
    "print(\"Q9 shape:\", grid_disp.shape)  # expected: (50,60,2)\n",
    "\n",
    "\n",
    "# 10. 3D displacement addition with batch using einsum\n",
    "I = torch.eye(3)\n",
    "grid = torch.randn(2, 10, 20, 30, 3)\n",
    "disp = torch.randn(2, 10, 20, 30, 3)\n",
    "# TODO\n",
    "grid_disp3 = torch.einsum('ij,ndhwj->ndhwi', I, grid) + disp\n",
    "print(\"Q10 shape:\", grid_disp3.shape)   # expected: (2,10,20,30,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8599160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c42f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3 shape: torch.Size([10, 20])\n",
      "Q4 shape: torch.Size([6])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486226f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5 shape: torch.Size([30, 40, 2])\n",
      "Q6 shape: torch.Size([5, 30, 40, 2])\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f79f554",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
